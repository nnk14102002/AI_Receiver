{"cells":[{"cell_type":"code","execution_count":1,"id":"I6dAcBEIjT9J","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32553,"status":"ok","timestamp":1742286314988,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"},"user_tz":-420},"id":"I6dAcBEIjT9J","outputId":"bf51048d-3fcf-46b2-c477-1a4e0b1b1e9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","id":"69d31188","metadata":{"id":"69d31188"},"source":["## GPU Configuration and Imports <a class=\"anchor\" id=\"GPU-Configuration-and-Imports\"></a>"]},{"cell_type":"code","execution_count":2,"id":"6393b2fe","metadata":{"id":"6393b2fe","executionInfo":{"status":"ok","timestamp":1742286319271,"user_tz":-420,"elapsed":4267,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["import os\n","if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n","    gpu_num = 0 # Use \"\" to use the CPU\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","import tensorflow as tf\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","    except RuntimeError as e:\n","        print(e)\n","# Avoid warnings from TensorFlow\n","tf.get_logger().setLevel('ERROR')\n"]},{"cell_type":"code","execution_count":3,"id":"zEoWxhRlzS4-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1742286319289,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"},"user_tz":-420},"id":"zEoWxhRlzS4-","outputId":"ebfae43b-7d83-40d5-b239-0a5d54bb285b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["gpus = tf.config.list_physical_devices('GPU')\n","print(gpus)"]},{"cell_type":"code","execution_count":4,"id":"6244a108","metadata":{"id":"6244a108","executionInfo":{"status":"ok","timestamp":1742286365494,"user_tz":-420,"elapsed":69,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","import time\n","import os\n","import pandas as pd\n","import datetime\n","import tqdm\n","import h5py\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Layer, Conv2D, LayerNormalization, SeparableConv2D, Normalization, BatchNormalization\n","from tensorflow.nn import relu"]},{"cell_type":"markdown","id":"6d33937d","metadata":{"id":"6d33937d"},"source":["## **Neural Receiver <a class=\"anchor\" id=\"Neural-Receiver\"></a>**"]},{"cell_type":"code","execution_count":5,"id":"mzrAkhF2067G","metadata":{"id":"mzrAkhF2067G","executionInfo":{"status":"ok","timestamp":1742286366909,"user_tz":-420,"elapsed":19,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["class ResidualBlock(Model):\n","    r\"\"\"\n","    This Keras layer implements a convolutional residual block made of two convolutional layers with ReLU activation, layer normalization, and a skip connection.\n","    The number of convolutional channels of the input must match the number of kernel of the convolutional layers ``num_conv_channel`` for the skip connection to work.\n","\n","    Input\n","    ------\n","    : [batch size, num time samples, num subcarriers, num_conv_channel], tf.float\n","        Input of the layer\n","\n","    Output\n","    -------\n","    : [batch size, num time samples, num subcarriers, num_conv_channel], tf.float\n","        Output of the layer\n","    \"\"\"\n","\n","    def build(self, input_shape):\n","\n","        self._layer_norm_1 = LayerNormalization(axis=[-1,-2,-3])\n","        self._conv_1 = Conv2D(filters= 128,\n","                              kernel_size=[3,3],\n","                              padding='same',\n","                              activation=None)\n","\n","        self._layer_norm_2 = LayerNormalization(axis=[-1,-2,-3])\n","        self._conv_2 = Conv2D(filters= 128,\n","                              kernel_size=[3,3],\n","                              padding='same',\n","                              activation=None)\n","\n","    def call(self, inputs):\n","        z = self._layer_norm_1(inputs)\n","        z = relu(z)\n","        z = self._conv_1(z)\n","        z = self._layer_norm_2(z)\n","        z = relu(z)\n","        z = self._conv_2(z) # [batch size, num time samples, num subcarriers, num_channels]\n","        # Skip connection\n","        z = z + inputs\n","\n","        return z\n","\n","class CustomNeuralReceiver(Model):\n","    r\"\"\"\n","    Keras layer implementing a residual convolutional neural receiver.\n","\n","    This neural receiver is fed with the post-DFT received samples, forming a resource grid of size num_of_symbols x fft_size, and computes LLRs on the transmitted coded bits.\n","    These LLRs can then be fed to an outer decoder to reconstruct the information bits.\n","\n","    Input\n","    ------\n","    y_no: [batch size, num ofdm symbols, num subcarriers, 2*num rx antenna + 1], tf.float32\n","        Concatenated received samples and noise variance.\n","(\n","    y : [batch size, num rx antenna, num ofdm symbols, num subcarriers], tf.complex\n","        Received post-DFT samples.\n","\n","    no : [batch size], tf.float32\n","        Noise variance. At training, a different noise variance value is sampled for each batch example.\n",")\n","    Output\n","    -------\n","    : [batch size, num ofdm symbols, num subcarriers, num_bits_per_symbol]\n","        LLRs on the transmitted bits.\n","    \"\"\"\n","\n","    def __init__(self, training = False):\n","        super(CustomNeuralReceiver, self).__init__()\n","        self._training = training\n","\n","    def build(self, input_shape):\n","\n","        # Input convolution\n","        self._input_conv = Conv2D(filters= 128,\n","                                  kernel_size=[3,3],\n","                                  padding='same',\n","                                  activation=None)\n","        # Residual blocks\n","        self._res_block_1 = ResidualBlock()\n","        self._res_block_2 = ResidualBlock()\n","        self._res_block_3 = ResidualBlock()\n","        self._res_block_4 = ResidualBlock()\n","        # Output conv\n","        self._output_conv = Conv2D(filters= 2,    # QPSK\n","                                   kernel_size=[3,3],\n","                                   padding='same',\n","                                   activation=None)\n","\n","    def call(self, inputs):\n","        # Split inputs size into 4RB-batchs.\n","        if self._training == False:\n","            padding_size = (-inputs.shape[1] % 48)\n","            padded_input_size = inputs.shape[1]\n","            if(padding_size != 0):\n","              padded_input_size = inputs.shape[1] + padding_size\n","              inputs = tf.concat([inputs, inputs[:,:padding_size,]],axis=1)\n","            inputs = tf.reshape(inputs, [-1,48,14,18])\n","\n","        # Input conv\n","        z = self._input_conv(inputs)\n","        # Residual blocks\n","        z = self._res_block_1(z)\n","        z = self._res_block_2(z)\n","        z = self._res_block_3(z)\n","        z = self._res_block_4(z)\n","        # Output conv\n","        z = self._output_conv(z)\n","\n","\n","        if self._training == False:\n","            z = tf.reshape(z, [-1,padded_input_size,14,2])\n","            if padding_size != 0:\n","              z = z[:,:-(padding_size),]\n","        z = tf.concat([z[...,0:3,:],z[...,4:11,:], z[...,12:14,:]],axis=-2)\n","        z = tf.transpose(z, perm=[0,2,1,3])\n","        z = tf.reshape(z, [z.shape[0],(z.shape[1]*z.shape[2]*z.shape[3])])\n","        return z"]},{"cell_type":"markdown","id":"SUpygto50gIo","metadata":{"id":"SUpygto50gIo"},"source":["#**Load Data**"]},{"cell_type":"markdown","id":"Sa9mIc4aDdHH","metadata":{"id":"Sa9mIc4aDdHH"},"source":["- Function to load and preprocess data (y - receiver data and c - label data)"]},{"cell_type":"code","execution_count":6,"id":"m4rTr-DecyGj","metadata":{"id":"m4rTr-DecyGj","executionInfo":{"status":"ok","timestamp":1742286640361,"user_tz":-420,"elapsed":266683,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["!mkdir hdf5\n","!cp -r /content/drive/MyDrive/Pusch_data/dataset/parquet .\n","!cp -r /content/drive/MyDrive/Pusch_data/dataset/hdf5/4RB_dataset_186k_samples.hdf5 /content/hdf5/"]},{"cell_type":"code","execution_count":7,"id":"IbHylYKrKfwQ","metadata":{"id":"IbHylYKrKfwQ","executionInfo":{"status":"ok","timestamp":1742286640385,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["def load_hdf5(parent_name, group_name):\n","    with h5py.File(f'{parent_name}.hdf5', \"r\") as f:\n","        b = f[f\"{group_name}_b\"][:]\n","        c = f[f\"{group_name}_c\"][:]\n","        y = f[f\"{group_name}_y\"][:]\n","        r = f[f\"{group_name}_r\"][:]\n","    return b, c, y, r\n","\n","def load_pickle(parent_name, group_name):\n","    \"\"\"Saves data to a pickle file.\"\"\"\n","    def load_from_pickle(filename):\n","        with open(filename, \"rb\") as f:\n","            return pickle.load(f)\n","\n","    b = load_from_pickle(f'{parent_name}/{group_name}.b.pkl')\n","    c = load_from_pickle(f'{parent_name}/{group_name}.c.pkl')\n","    y = load_from_pickle(f'{parent_name}/{group_name}.y.pkl')\n","    r = load_from_pickle(f'{parent_name}/{group_name}.r.pkl')\n","\n","    return b, c, y, r\n","\n","def data_loader(df, dir, saved_dataset='hdf5'):\n","    assert saved_dataset in ['hdf5', 'pickle'], \"saved data set should be 'pickle' or 'hdf5'.\"\n","    assert df['nTBSize'].nunique() == 1, \"Not all elements have the same TB size.\"\n","    # assert df['Dmrs_mask'].map(len).nunique() == 1, \"Not all elements have the same number of Dmrs/Data symbols.\"\n","\n","    for pusch_record in df.itertuples():\n","        data_filename = pusch_record.Data_filename\n","        data_dirname = pusch_record.Data_dirname\n","        esno_db = pusch_record.Esno_db\n","        index = pusch_record.index\n","        if saved_dataset == 'hdf5':\n","            b,c,y, r = load_hdf5(f'{dir}/{data_dirname}', data_filename)\n","        else:\n","            b,c,y, r = load_pickle(f'{dir}/{data_dirname}', data_filename)\n","        yield index, esno_db, c, y, b, r\n","\n","def preprocessing(index, esno_db, c, y, b, r):\n","    y = tf.concat([tf.math.real(y), tf.math.imag(y)], axis = 0)\n","    y = tf.transpose(y, perm=[2,1,0])\n","    y = (y - tf.reduce_mean(y)) / tf.math.reduce_std(y)\n","    r = tf.concat([tf.math.real(r), tf.math.imag(r)], axis = 0)\n","    r = tf.transpose(r, perm=[2,1,0])\n","\n","    y_r = tf.concat([y, r], axis = -1)\n","    return index, esno_db, c, y, b, r, y_r\n","\n"]},{"cell_type":"code","source":["import os\n","from concurrent.futures import ThreadPoolExecutor"],"metadata":{"id":"CV1f3Pp6wkZJ","executionInfo":{"status":"ok","timestamp":1742286661640,"user_tz":-420,"elapsed":50,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"id":"CV1f3Pp6wkZJ","execution_count":10,"outputs":[]},{"cell_type":"code","source":["def load_data_in_parallel(pusch_record, dir, saved_dataset):\n","    data_filename = pusch_record.Data_filename\n","    data_dirname = pusch_record.Data_dirname\n","    esno_db = pusch_record.Esno_db\n","    index = pusch_record.index\n","\n","    data_path = os.path.join(dir, data_dirname)\n","\n","    if saved_dataset == 'hdf5':\n","        b, c, y, r = load_hdf5(data_path, data_filename)\n","    else:\n","        b, c, y, r = load_pickle(data_path, data_filename)\n","\n","    return index, esno_db, c, y, b, r\n","\n","def data_loader(df, dir, saved_dataset='hdf5', max_workers=4):\n","    assert saved_dataset in ['hdf5', 'pickle'], \"saved data set should be 'pickle' or 'hdf5'.\"\n","    assert df['nTBSize'].nunique() == 1, \"Not all elements have the same TB size.\"\n","\n","    # Precompute the directory path to avoid repeated operations\n","    data_dir = os.path.abspath(dir)\n","\n","    # Use ThreadPoolExecutor to load data in parallel (for I/O-bound tasks)\n","    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n","        results = executor.map(lambda pusch_record: load_data_in_parallel(pusch_record, data_dir, saved_dataset), df.itertuples())\n","\n","    # Yield results from the executor\n","    for result in results:\n","        yield result"],"metadata":{"id":"mYIXrs7owl2C","executionInfo":{"status":"ok","timestamp":1742286662207,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"id":"mYIXrs7owl2C","execution_count":11,"outputs":[]},{"cell_type":"markdown","id":"Dge6oPz9Dgfh","metadata":{"id":"Dge6oPz9Dgfh"},"source":["**Load Data into Dataset**"]},{"cell_type":"code","execution_count":null,"id":"6S4gKSEOf3vL","metadata":{"id":"6S4gKSEOf3vL"},"outputs":[],"source":["# NUM_SAMPLE = 4"]},{"cell_type":"markdown","id":"wjD_yMNG9KJ0","metadata":{"id":"wjD_yMNG9KJ0"},"source":["- Data training has same size [ 4 x 12 ] (4RB Data Resource Grid). Then split into smaller blocks corresponding to nRB before training.\n","\n","\n","(Below is doing 1RB training)\n","\n","- Drag the PUSCH_Data drive to your drive then edit the path below:\n","\n","\n","1.   pickles_dir: Dir to data folder\n","2.   parquet_path: Dir to meta data folder\n","- See document for details\n","\n","\n"]},{"cell_type":"markdown","source":["* **Setup dataset_dir**"],"metadata":{"id":"vMtoYhuDMJcj"},"id":"vMtoYhuDMJcj"},{"cell_type":"code","source":["dataset_dir = f'/content/'\n","pickles_dir = f'{dataset_dir}/pickle'\n","hdf5_dir = f'{dataset_dir}/hdf5'\n","parquet_dir = f'{dataset_dir}/parquet'\n","\n","parquet_name = '4RB_dataset_186k_samples' #4RB"],"metadata":{"id":"1ffGbAwJL95D","executionInfo":{"status":"ok","timestamp":1742286664824,"user_tz":-420,"elapsed":15,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"id":"1ffGbAwJL95D","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["* **Read and split data_folder into train and test set**"],"metadata":{"id":"2ELB_xfsMUAQ"},"id":"2ELB_xfsMUAQ"},{"cell_type":"code","execution_count":13,"id":"X1B5XiP-1ra9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":625,"status":"ok","timestamp":1742286667515,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"},"user_tz":-420},"id":"X1B5XiP-1ra9","outputId":"1c867bf5-e5d3-450e-bb13-ac3b429da886"},"outputs":[{"output_type":"stream","name":"stdout","text":["Low: Total Size: 66044 sample, Test Size: 3303 sample, Train Size: 62741 sample\n","Mid: Total Size: 60040 sample, Test Size: 3002 sample, Train Size: 57038 sample\n","High: Total Size: 60040 sample, Test Size: 3002 sample, Train Size: 57038 sample\n"]}],"source":["df = pd.read_parquet(f'{parquet_dir}/{parquet_name}.parquet', engine=\"pyarrow\")\n","df = df.reset_index()\n","\n","split_rate = 0.95\n","\n","df_low = df[df['Esno_db'] <= -5]\n","df_mid = df[(df['Esno_db'] <= 0) & (df['Esno_db'] > -5)]\n","df_high = df[df['Esno_db'] > -0]\n","\n","NUM_SAMPLE_LOW = len(df_low)\n","NUM_SAMPLE_MID = len(df_mid)\n","NUM_SAMPLE_HIGH = len(df_high)\n","\n","df_low = df_low.sample(frac=1)\n","df_mid = df_mid.sample(frac=1)\n","df_high = df_high.sample(frac=1)\n","\n","test_df_low = df_low.iloc[int(NUM_SAMPLE_LOW*split_rate):]\n","train_df_low = df_low.iloc[:int(NUM_SAMPLE_LOW*split_rate)]\n","\n","test_df_mid = df_mid.iloc[int(NUM_SAMPLE_MID*split_rate):]\n","train_df_mid = df_mid.iloc[:int(NUM_SAMPLE_MID*split_rate)]\n","\n","test_df_high = df_high.iloc[int(NUM_SAMPLE_HIGH*split_rate):]\n","train_df_high = df_high.iloc[:int(NUM_SAMPLE_HIGH*split_rate)]\n","\n","print(f\"Low: Total Size: {len(df_low)} sample, Test Size: {len(test_df_low)} sample, Train Size: {len(train_df_low)} sample\")\n","print(f\"Mid: Total Size: {len(df_mid)} sample, Test Size: {len(test_df_mid)} sample, Train Size: {len(train_df_mid)} sample\")\n","print(f\"High: Total Size: {len(df_high)} sample, Test Size: {len(test_df_high)} sample, Train Size: {len(train_df_high)} sample\")\n"]},{"cell_type":"markdown","source":["* **Load data into Dataset object**"],"metadata":{"id":"dWtlXpeANKG9"},"id":"dWtlXpeANKG9"},{"cell_type":"code","source":["def load_data(train_df, test_df, hdf5_dir, batch_train, batch_test):\n","  train_set = tf.data.Dataset.from_generator(\n","            lambda: data_loader(train_df, hdf5_dir),\n","            output_types=(tf.int32, tf.float32, tf.float32, tf.complex64, tf.float32, tf.complex64))\n","\n","  train_set = train_set.cache()\n","  train_set = train_set.prefetch(tf.data.AUTOTUNE)\n","  train_set = train_set.map(preprocessing).batch(batch_train)\n","\n","  # Load test_data into Dataset\n","  test_set = tf.data.Dataset.from_generator(\n","              lambda: data_loader(test_df, hdf5_dir),\n","              output_types=(tf.int32, tf.float32, tf.float32, tf.complex64, tf.float32, tf.complex64))\n","\n","  test_set = test_set.cache()\n","  test_set = test_set.prefetch(tf.data.AUTOTUNE)\n","  test_set = test_set.map(preprocessing).batch(batch_test)\n","  return train_set, test_set\n"],"metadata":{"id":"YVRlHskV_-9P","executionInfo":{"status":"ok","timestamp":1742286668884,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"id":"YVRlHskV_-9P","execution_count":14,"outputs":[]},{"cell_type":"code","source":["BATCH_TRAIN = 256\n","BATCH_TEST = 64\n","\n","train_set_low, test_set_low = load_data(train_df_low, test_df_low, hdf5_dir, BATCH_TRAIN, BATCH_TEST)\n","train_set_mid, test_set_mid = load_data(train_df_mid, test_df_mid, hdf5_dir, BATCH_TRAIN, BATCH_TEST)\n","train_set_high, test_set_high = load_data(train_df_high, test_df_high, hdf5_dir, BATCH_TRAIN, BATCH_TEST)\n","\n"],"metadata":{"id":"AEAdU7XEGLsp","executionInfo":{"status":"ok","timestamp":1742286672292,"user_tz":-420,"elapsed":550,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"id":"AEAdU7XEGLsp","execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"id":"gXh2J0zEN__s","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145089,"status":"ok","timestamp":1742286824641,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"},"user_tz":-420},"id":"gXh2J0zEN__s","outputId":"4c4fe93e-910f-439d-f775-3d926bdc2d89"},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(39, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(58, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(64, 48, 14, 16)\n","(58, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(256, 48, 14, 16)\n","(206, 48, 14, 16)\n"]}],"source":["# First load data for accelerating\n","for n, (index, esno_db, c, y, b, r, y_r) in enumerate(test_set_low):\n","    print(y.shape)\n","\n","for n, (index, esno_db, c, y, b, r, y_r) in enumerate(test_set_mid):\n","    print(y.shape)\n","\n","for n, (index, esno_db, c, y, b, r, y_r) in enumerate(test_set_high):\n","    print(y.shape)\n","\n","for n, (index, esno_db, c, y, b, r, y_r) in enumerate(train_set_high):\n","    print(y.shape)\n"]},{"cell_type":"code","execution_count":null,"id":"0tUe-BFkaWx4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1741763481097,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"},"user_tz":-420},"id":"0tUe-BFkaWx4","outputId":"eabaddb7-b151-4f0d-9892-1f94e983df0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(0.12375993, shape=(), dtype=float32)\n"]}],"source":["# model._training = False\n","# llr = model(y_r)\n","# loss = loss_cal(llr, c)\n","# print(loss)"]},{"cell_type":"markdown","id":"zqq2MzTGo2JP","metadata":{"id":"zqq2MzTGo2JP"},"source":["- Checking size of a sample data in Dataset\n","- Preprocessing is called when load Data"]},{"cell_type":"markdown","id":"PJTxVc3qXrct","metadata":{"id":"PJTxVc3qXrct"},"source":["#**Training Model**"]},{"cell_type":"markdown","id":"3LwiUPJm-9NK","metadata":{"id":"3LwiUPJm-9NK"},"source":["\n","\n","*   Creat Model and Optimizer Instance\n","*   Set mode of \"pretrained\" ( True to load pretrained weights if exist )"]},{"cell_type":"code","execution_count":17,"id":"GfAq_2mp5Pkc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"elapsed":2843,"status":"ok","timestamp":1742286827509,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"},"user_tz":-420},"id":"GfAq_2mp5Pkc","outputId":"8c9bcbf9-9b11-446b-e4ca-debba65ef355"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"custom_neural_receiver\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_neural_receiver\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m20,864\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block (\u001b[38;5;33mResidualBlock\u001b[0m)       │ ?                           │         \u001b[38;5;34m639,232\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block_1 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ ?                           │         \u001b[38;5;34m639,232\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block_2 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ ?                           │         \u001b[38;5;34m639,232\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block_3 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ ?                           │         \u001b[38;5;34m639,232\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m2,306\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,864</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)       │ ?                           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,232</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ ?                           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,232</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ ?                           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,232</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ residual_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ ?                           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,232</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,306</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,580,098\u001b[0m (9.84 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,098</span> (9.84 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,580,098\u001b[0m (9.84 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,098</span> (9.84 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["model = CustomNeuralReceiver(training = True)\n","inputs = tf.zeros([1,48,14,18])\n","model(inputs)\n","model.summary()\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","pretrained = False"]},{"cell_type":"code","execution_count":18,"id":"_F1sbTBgA9lA","metadata":{"id":"_F1sbTBgA9lA","executionInfo":{"status":"ok","timestamp":1742286827513,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["# Define our metrics\n","train_batch_loss = tf.keras.metrics.Mean('Epoch_train_loss', dtype=tf.float32)\n","\n","val_batch_loss_low = tf.keras.metrics.Mean('Epoch_val_loss_low', dtype=tf.float32)\n","val_batch_loss_mid = tf.keras.metrics.Mean('Epoch_val_loss_mid', dtype=tf.float32)\n","val_batch_loss_high = tf.keras.metrics.Mean('Epoch_val_loss_high', dtype=tf.float32)\n"]},{"cell_type":"markdown","id":"s5D-1p8QpyWI","metadata":{"id":"s5D-1p8QpyWI"},"source":["- **Define Train_step and Loss_cal**\n","\n","\n","\n"]},{"cell_type":"code","execution_count":19,"id":"9WHkZ-9d555E","metadata":{"id":"9WHkZ-9d555E","executionInfo":{"status":"ok","timestamp":1742286827516,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["def loss_cal(pred, labels):\n","  bce = tf.nn.sigmoid_cross_entropy_with_logits(labels, pred)\n","  bce = tf.reduce_mean(bce)\n","  loss = bce\n","  return loss\n","\n","\n","#train model with nRB\n","@tf.function\n","def train_step(inputs, labels):\n","  with tf.GradientTape() as tape:\n","    llr = model(inputs)\n","    loss = loss_cal(llr, labels)\n","  weights = model.trainable_weights\n","  grads = tape.gradient(loss, weights)\n","  optimizer.apply_gradients(zip(grads, weights))\n","  # train_accuracy(labels, llr)\n","  return loss\n","\n","#test model with nRB\n","@tf.function\n","def val_step(inputs, labels):\n","  llr = model(inputs)\n","  loss = loss_cal(llr, labels)\n","  # train_accuracy(labels, llr)\n","  return loss"]},{"cell_type":"markdown","id":"lshclj0Ks5Pa","metadata":{"id":"lshclj0Ks5Pa"},"source":["- **Load and save pretrained Model**"]},{"cell_type":"code","execution_count":20,"id":"8M5r4N05AkAn","metadata":{"id":"8M5r4N05AkAn","executionInfo":{"status":"ok","timestamp":1742286827520,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["def load_weights(model, pretrained_weights_path):\n","    # Build Model with random input\n","    # Load weights\n","  with open(pretrained_weights_path, 'rb') as f:\n","    weights = pickle.load(f)\n","    model.set_weights(weights)\n","    print(f\"Loaded pretrained weights from {pretrained_weights_path}\")\n","\n","def save_weights(model, model_folder_path, model_file_name):\n","    # Save the weights in a file\n","    model_weights_path = os.path.join(model_folder_path, model_file_name)\n","    weights = model.get_weights()\n","    with open(model_weights_path, 'wb') as f:\n","        pickle.dump(weights, f)\n","\n","def save_trainable_weights(model, model_folder_path, model_file_name):\n","    # Save the weights in a file\n","    model_weights_path = os.path.join(model_folder_path, model_file_name)\n","    weights = model.trainable_weights\n","    with open(model_weights_path, 'wb') as f:\n","        pickle.dump(weights, f)"]},{"cell_type":"code","execution_count":null,"id":"O5r3NrSIse5z","metadata":{"id":"O5r3NrSIse5z"},"outputs":[],"source":["if pretrained:\n","  pretrained_weights_path = '/content/drive/MyDrive/AI_for_PUSCH/VHT_neural_receiver/weight_4RB_normalize_with_DMRS_org.pkl'\n","  load_weights(model, pretrained_weights_path)"]},{"cell_type":"markdown","id":"NCwCmdyQRbf-","metadata":{"id":"NCwCmdyQRbf-"},"source":["- **Training model**"]},{"cell_type":"code","execution_count":null,"id":"NN8aU0OIEVOm","metadata":{"id":"NN8aU0OIEVOm"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":21,"id":"GX1JB3fpj9PB","metadata":{"id":"GX1JB3fpj9PB","executionInfo":{"status":"ok","timestamp":1742286828248,"user_tz":-420,"elapsed":725,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"outputs":[],"source":["#Initialize folder log for tensorboard\n","current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","#Setup log_path\n","train_log_dir = '/content/drive/MyDrive/AI_for_PUSCH/logs/gradient_tape/' + current_time + '/train'\n","train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n","\n","val_log_dir = '/content/drive/MyDrive/AI_for_PUSCH/logs/gradient_tape/' + current_time + '/val'\n","val_summary_writer = tf.summary.create_file_writer(val_log_dir)"]},{"cell_type":"markdown","id":"LZWckpuojhTE","metadata":{"id":"LZWckpuojhTE"},"source":["* ***If using VSCode, run \"tensorboard --logdir /log_path\" in terminal***"]},{"cell_type":"code","execution_count":null,"id":"tx2RaLbhEn5W","metadata":{"id":"tx2RaLbhEn5W"},"outputs":[],"source":["%tensorboard --logdir /content/drive/MyDrive/AI_for_PUSCH/logs/gradient_tape/"]},{"cell_type":"markdown","source":["\n","\n","*   **Define global params for training**\n","\n"],"metadata":{"id":"tYvC5M2OTgGu"},"id":"tYvC5M2OTgGu"},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","# Define num EPOCHS, Model_path, Model_name to save model during training\n","EPOCHS = 1000\n","SAVE_AFTER_NUM_EPOCH = 2\n","model_folder_path = \"/content/drive/MyDrive/AI_for_PUSCH/VHT_neural_receiver/\"    #Custom here"],"metadata":{"id":"pU1wnUKbTXW0","executionInfo":{"status":"ok","timestamp":1742286828256,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nam Khánh","userId":"17195362204309494329"}}},"id":"pU1wnUKbTXW0","execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"d9nR6d7b_zwW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9nR6d7b_zwW","outputId":"cbd322b1-6b75-4408-8e5e-070dbf01da24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, \n","Epoch 0, Train_Loss: 0.6900, Val_Loss_low: 0.6830, Val_Loss_mid: 0.6504, Val_Loss_high: 0.6223, Time taken: 65.29\n","Save model at epoch 0\n","Epoch 1, \n","Epoch 1, Train_Loss: 0.6482, Val_Loss_low: 0.6350, Val_Loss_mid: 0.5261, Val_Loss_high: 0.4255, Time taken: 65.10\n","Save model at epoch 1\n","Epoch 2, \n","Epoch 2, Train_Loss: 0.6216, Val_Loss_low: 0.6206, Val_Loss_mid: 0.4985, Val_Loss_high: 0.4051, Time taken: 65.15\n","Save model at epoch 2\n","Epoch 3, \n","Epoch 3, Train_Loss: 0.5964, Val_Loss_low: 0.6010, Val_Loss_mid: 0.4629, Val_Loss_high: 0.3548, Time taken: 65.13\n","Save model at epoch 3\n","Epoch 4, \n","Epoch 4, Train_Loss: 0.5718, Val_Loss_low: 0.5675, Val_Loss_mid: 0.3982, Val_Loss_high: 0.2605, Time taken: 65.16\n","Save model at epoch 4\n","Epoch 5, \n","Epoch 5, Train_Loss: 0.5602, Val_Loss_low: 0.5758, Val_Loss_mid: 0.3938, Val_Loss_high: 0.2501, Time taken: 65.15\n","Save model at epoch 5\n","Epoch 6, \n","Epoch 6, Train_Loss: 0.5417, Val_Loss_low: 0.5689, Val_Loss_mid: 0.3756, Val_Loss_high: 0.2413, Time taken: 65.16\n","Save model at epoch 6\n","Epoch 7, \n","Epoch 7, Train_Loss: 0.5218, Val_Loss_low: 0.5395, Val_Loss_mid: 0.3160, Val_Loss_high: 0.1854, Time taken: 65.16\n","Save model at epoch 7\n","Epoch 8, \n","Epoch 8, Train_Loss: 0.5036, Val_Loss_low: 0.5025, Val_Loss_mid: 0.2820, Val_Loss_high: 0.1601, Time taken: 65.19\n","Save model at epoch 8\n","Epoch 9, \n","Epoch 9, Train_Loss: 0.4877, Val_Loss_low: 0.5113, Val_Loss_mid: 0.2773, Val_Loss_high: 0.1618, Time taken: 65.18\n","Epoch 10, \n","Epoch 10, Train_Loss: 0.4759, Val_Loss_low: 0.5091, Val_Loss_mid: 0.2736, Val_Loss_high: 0.1627, Time taken: 65.20\n","Epoch 11, \n","Epoch 11, Train_Loss: 0.4650, Val_Loss_low: 0.4741, Val_Loss_mid: 0.2466, Val_Loss_high: 0.1424, Time taken: 65.22\n","Save model at epoch 11\n","Epoch 12, \n","Epoch 12, Train_Loss: 0.4554, Val_Loss_low: 0.4761, Val_Loss_mid: 0.2383, Val_Loss_high: 0.1432, Time taken: 65.07\n","Epoch 13, \n","Epoch 13, Train_Loss: 0.4493, Val_Loss_low: 0.4795, Val_Loss_mid: 0.2338, Val_Loss_high: 0.1379, Time taken: 65.23\n","Save model at epoch 13\n","Epoch 14, \n","Epoch 14, Train_Loss: 0.4427, Val_Loss_low: 0.4581, Val_Loss_mid: 0.2188, Val_Loss_high: 0.1271, Time taken: 65.24\n","Save model at epoch 14\n","Epoch 15, \n","Epoch 15, Train_Loss: 0.4359, Val_Loss_low: 0.4625, Val_Loss_mid: 0.2267, Val_Loss_high: 0.1458, Time taken: 65.24\n","Epoch 16, \n","Epoch 16, Train_Loss: 0.4306, Val_Loss_low: 0.4523, Val_Loss_mid: 0.2160, Val_Loss_high: 0.1374, Time taken: 65.21\n","Epoch 17, \n","Epoch 17, Train_Loss: 0.4256, Val_Loss_low: 0.4474, Val_Loss_mid: 0.2094, Val_Loss_high: 0.1358, Time taken: 65.05\n","Epoch 18, \n","Epoch 18, Train_Loss: 0.4207, Val_Loss_low: 0.4654, Val_Loss_mid: 0.2153, Val_Loss_high: 0.1421, Time taken: 65.11\n","Epoch 19, \n","Epoch 19, Train_Loss: 0.4192, Val_Loss_low: 0.4635, Val_Loss_mid: 0.2020, Val_Loss_high: 0.1204, Time taken: 65.16\n","Save model at epoch 19\n","Epoch 20, \n","Epoch 20, Train_Loss: 0.4177, Val_Loss_low: 0.4516, Val_Loss_mid: 0.2095, Val_Loss_high: 0.1397, Time taken: 65.12\n","Epoch 21, \n","Epoch 21, Train_Loss: 0.4130, Val_Loss_low: 0.4379, Val_Loss_mid: 0.1978, Val_Loss_high: 0.1261, Time taken: 65.21\n","Epoch 22, \n","Epoch 22, Train_Loss: 0.4062, Val_Loss_low: 0.4336, Val_Loss_mid: 0.1968, Val_Loss_high: 0.1306, Time taken: 65.21\n","Epoch 23, \n","Epoch 23, Train_Loss: 0.4031, Val_Loss_low: 0.4336, Val_Loss_mid: 0.1918, Val_Loss_high: 0.1234, Time taken: 65.23\n","Epoch 24, \n","Epoch 24, Train_Loss: 0.4010, Val_Loss_low: 0.4313, Val_Loss_mid: 0.1953, Val_Loss_high: 0.1304, Time taken: 65.22\n","Epoch 25, \n","Epoch 25, Train_Loss: 0.4010, Val_Loss_low: 0.4431, Val_Loss_mid: 0.1923, Val_Loss_high: 0.1156, Time taken: 65.23\n","Save model at epoch 25\n","Epoch 26, \n","Epoch 26, Train_Loss: 0.3981, Val_Loss_low: 0.4266, Val_Loss_mid: 0.1810, Val_Loss_high: 0.1102, Time taken: 65.25\n","Save model at epoch 26\n","Epoch 27, \n","Epoch 27, Train_Loss: 0.3938, Val_Loss_low: 0.4223, Val_Loss_mid: 0.1795, Val_Loss_high: 0.1167, Time taken: 65.24\n","Epoch 28, \n","Epoch 28, Train_Loss: 0.3914, Val_Loss_low: 0.4239, Val_Loss_mid: 0.1791, Val_Loss_high: 0.1156, Time taken: 65.23\n","Epoch 29, \n","Epoch 29, Train_Loss: 0.3901, Val_Loss_low: 0.4251, Val_Loss_mid: 0.1775, Val_Loss_high: 0.1122, Time taken: 65.23\n","Epoch 30, \n","Epoch 30, Train_Loss: 0.3878, Val_Loss_low: 0.4314, Val_Loss_mid: 0.1782, Val_Loss_high: 0.1107, Time taken: 65.25\n","Epoch 31, \n","Epoch 31, Train_Loss: 0.3872, Val_Loss_low: 0.4387, Val_Loss_mid: 0.1857, Val_Loss_high: 0.1165, Time taken: 65.23\n","Epoch 32, \n","Epoch 32, Train_Loss: 0.3865, Val_Loss_low: 0.4312, Val_Loss_mid: 0.1756, Val_Loss_high: 0.1093, Time taken: 65.23\n","Save model at epoch 32\n","Epoch 33, \n","Epoch 33, Train_Loss: 0.3855, Val_Loss_low: 0.4355, Val_Loss_mid: 0.1729, Val_Loss_high: 0.1006, Time taken: 65.22\n","Save model at epoch 33\n","Epoch 34, \n","Epoch 34, Train_Loss: 0.3842, Val_Loss_low: 0.4238, Val_Loss_mid: 0.1670, Val_Loss_high: 0.1045, Time taken: 65.06\n","Epoch 35, \n","Epoch 35, Train_Loss: 0.3796, Val_Loss_low: 0.4249, Val_Loss_mid: 0.1684, Val_Loss_high: 0.1092, Time taken: 65.16\n","Epoch 36, \n","Epoch 36, Train_Loss: 0.3776, Val_Loss_low: 0.4197, Val_Loss_mid: 0.1687, Val_Loss_high: 0.1129, Time taken: 65.13\n","Epoch 37, \n","Epoch 37, Train_Loss: 0.3792, Val_Loss_low: 0.4324, Val_Loss_mid: 0.1706, Val_Loss_high: 0.1101, Time taken: 65.11\n","Epoch 38, \n","Epoch 38, Train_Loss: 0.3785, Val_Loss_low: 0.4238, Val_Loss_mid: 0.1716, Val_Loss_high: 0.1162, Time taken: 65.10\n","Epoch 39, \n","Epoch 39, Train_Loss: 0.3766, Val_Loss_low: 0.4074, Val_Loss_mid: 0.1605, Val_Loss_high: 0.1016, Time taken: 65.12\n","Epoch 40, \n","Epoch 40, Train_Loss: 0.3740, Val_Loss_low: 0.4063, Val_Loss_mid: 0.1571, Val_Loss_high: 0.0974, Time taken: 65.14\n","Save model at epoch 40\n","Epoch 41, \n","Epoch 41, Train_Loss: 0.3719, Val_Loss_low: 0.4085, Val_Loss_mid: 0.1602, Val_Loss_high: 0.1019, Time taken: 65.11\n","Epoch 42, \n","Epoch 42, Train_Loss: 0.3714, Val_Loss_low: 0.4147, Val_Loss_mid: 0.1606, Val_Loss_high: 0.0982, Time taken: 65.09\n","Epoch 43, \n","Epoch 43, Train_Loss: 0.3702, Val_Loss_low: 0.4140, Val_Loss_mid: 0.1602, Val_Loss_high: 0.0984, Time taken: 65.13\n","Epoch 44, \n","Epoch 44, Train_Loss: 0.3720, Val_Loss_low: 0.4171, Val_Loss_mid: 0.1631, Val_Loss_high: 0.1004, Time taken: 65.15\n","Epoch 45, \n","Epoch 45, Train_Loss: 0.3703, Val_Loss_low: 0.4099, Val_Loss_mid: 0.1578, Val_Loss_high: 0.0959, Time taken: 65.15\n","Save model at epoch 45\n","Epoch 46, \n","Epoch 46, Train_Loss: 0.3684, Val_Loss_low: 0.4139, Val_Loss_mid: 0.1603, Val_Loss_high: 0.1036, Time taken: 65.14\n","Epoch 47, \n","Epoch 47, Train_Loss: 0.3661, Val_Loss_low: 0.4126, Val_Loss_mid: 0.1551, Val_Loss_high: 0.0978, Time taken: 65.13\n","Epoch 48, \n","Epoch 48, Train_Loss: 0.3635, Val_Loss_low: 0.4176, Val_Loss_mid: 0.1582, Val_Loss_high: 0.1058, Time taken: 65.16\n","Epoch 49, \n","Epoch 49, Train_Loss: 0.3617, Val_Loss_low: 0.4180, Val_Loss_mid: 0.1633, Val_Loss_high: 0.1147, Time taken: 65.13\n","Epoch 50, \n","Epoch 50, Train_Loss: 0.3607, Val_Loss_low: 0.4160, Val_Loss_mid: 0.1627, Val_Loss_high: 0.1151, Time taken: 65.14\n","Epoch 51, \n","Epoch 51, Train_Loss: 0.3611, Val_Loss_low: 0.4188, Val_Loss_mid: 0.1583, Val_Loss_high: 0.1065, Time taken: 65.13\n","Epoch 52, \n","Epoch 52, Train_Loss: 0.3627, Val_Loss_low: 0.4152, Val_Loss_mid: 0.1492, Val_Loss_high: 0.0901, Time taken: 65.11\n","Save model at epoch 52\n","Epoch 53, \n","Epoch 53, Train_Loss: 0.3629, Val_Loss_low: 0.4118, Val_Loss_mid: 0.1518, Val_Loss_high: 0.0905, Time taken: 65.14\n","Epoch 54, \n","Epoch 54, Train_Loss: 0.3616, Val_Loss_low: 0.4028, Val_Loss_mid: 0.1484, Val_Loss_high: 0.0879, Time taken: 65.14\n","Save model at epoch 54\n","Epoch 55, \n","Epoch 55, Train_Loss: 0.3608, Val_Loss_low: 0.4036, Val_Loss_mid: 0.1450, Val_Loss_high: 0.0822, Time taken: 65.26\n","Save model at epoch 55\n","Epoch 56, \n","Epoch 56, Train_Loss: 0.3596, Val_Loss_low: 0.4063, Val_Loss_mid: 0.1491, Val_Loss_high: 0.0903, Time taken: 65.21\n","Epoch 57, \n","Epoch 57, Train_Loss: 0.3588, Val_Loss_low: 0.4035, Val_Loss_mid: 0.1484, Val_Loss_high: 0.0896, Time taken: 65.13\n","Epoch 58, \n","Epoch 58, Train_Loss: 0.3593, Val_Loss_low: 0.4035, Val_Loss_mid: 0.1479, Val_Loss_high: 0.0887, Time taken: 65.12\n","Epoch 59, \n","Epoch 59, Train_Loss: 0.3591, Val_Loss_low: 0.4012, Val_Loss_mid: 0.1434, Val_Loss_high: 0.0811, Time taken: 65.12\n","Save model at epoch 59\n","Epoch 60, \n","Epoch 60, Train_Loss: 0.3585, Val_Loss_low: 0.4136, Val_Loss_mid: 0.1540, Val_Loss_high: 0.0949, Time taken: 65.11\n","Epoch 61, \n","Epoch 61, Train_Loss: 0.3587, Val_Loss_low: 0.4333, Val_Loss_mid: 0.1703, Val_Loss_high: 0.1161, Time taken: 65.13\n","Epoch 62, \n","Epoch 62, Train_Loss: 0.3588, Val_Loss_low: 0.4089, Val_Loss_mid: 0.1508, Val_Loss_high: 0.0970, Time taken: 65.14\n","Epoch 63, \n","Epoch 63, Train_Loss: 0.3570, Val_Loss_low: 0.4098, Val_Loss_mid: 0.1489, Val_Loss_high: 0.0948, Time taken: 65.14\n","Epoch 64, \n","Epoch 64, Train_Loss: 0.3559, Val_Loss_low: 0.4109, Val_Loss_mid: 0.1487, Val_Loss_high: 0.0965, Time taken: 65.12\n","Epoch 65, \n","Epoch 65, Train_Loss: 0.3541, Val_Loss_low: 0.4103, Val_Loss_mid: 0.1504, Val_Loss_high: 0.1007, Time taken: 65.16\n","Epoch 66, \n","Epoch 66, Train_Loss: 0.3520, Val_Loss_low: 0.4075, Val_Loss_mid: 0.1503, Val_Loss_high: 0.1031, Time taken: 65.14\n","Epoch 67, \n","Epoch 67, Train_Loss: 0.3499, Val_Loss_low: 0.4112, Val_Loss_mid: 0.1511, Val_Loss_high: 0.1030, Time taken: 65.11\n","Epoch 68, \n","Epoch 68, Train_Loss: 0.3496, Val_Loss_low: 0.4127, Val_Loss_mid: 0.1508, Val_Loss_high: 0.1025, Time taken: 65.13\n","Epoch 69, \n","Epoch 69, Train_Loss: 0.3488, Val_Loss_low: 0.4155, Val_Loss_mid: 0.1500, Val_Loss_high: 0.1012, Time taken: 65.15\n","Epoch 70, \n","Epoch 70, Train_Loss: 0.3477, Val_Loss_low: 0.4146, Val_Loss_mid: 0.1517, Val_Loss_high: 0.1041, Time taken: 65.15\n","Epoch 71, \n","Epoch 71, Train_Loss: 0.3468, Val_Loss_low: 0.4194, Val_Loss_mid: 0.1539, Val_Loss_high: 0.1076, Time taken: 65.14\n","Epoch 72, \n","Epoch 72, Train_Loss: 0.3481, Val_Loss_low: 0.4239, Val_Loss_mid: 0.1470, Val_Loss_high: 0.0942, Time taken: 65.11\n","Epoch 73, \n","Epoch 73, Train_Loss: 0.3488, Val_Loss_low: 0.4118, Val_Loss_mid: 0.1526, Val_Loss_high: 0.1040, Time taken: 65.14\n","Epoch 74, \n","Epoch 74, Train_Loss: 0.3485, Val_Loss_low: 0.4026, Val_Loss_mid: 0.1509, Val_Loss_high: 0.1017, Time taken: 65.17\n","Epoch 75, \n","Epoch 75, Train_Loss: 0.3484, Val_Loss_low: 0.4059, Val_Loss_mid: 0.1513, Val_Loss_high: 0.0997, Time taken: 65.15\n","Epoch 76, \n","Epoch 76, Train_Loss: 0.3478, Val_Loss_low: 0.4247, Val_Loss_mid: 0.1495, Val_Loss_high: 0.0964, Time taken: 65.25\n","Epoch 77, \n","Epoch 77, Train_Loss: 0.3489, Val_Loss_low: 0.4314, Val_Loss_mid: 0.1665, Val_Loss_high: 0.1171, Time taken: 65.20\n","Epoch 78, \n","Epoch 78, Train_Loss: 0.3497, Val_Loss_low: 0.4016, Val_Loss_mid: 0.1388, Val_Loss_high: 0.0771, Time taken: 65.22\n","Save model at epoch 78\n","Epoch 79, \n","Epoch 79, Train_Loss: 0.3494, Val_Loss_low: 0.4092, Val_Loss_mid: 0.1401, Val_Loss_high: 0.0804, Time taken: 65.20\n","Epoch 80, \n","Epoch 80, Train_Loss: 0.3499, Val_Loss_low: 0.4164, Val_Loss_mid: 0.1404, Val_Loss_high: 0.0767, Time taken: 65.21\n","Save model at epoch 80\n","Epoch 81, \n","Epoch 81, Train_Loss: 0.3499, Val_Loss_low: 0.4093, Val_Loss_mid: 0.1375, Val_Loss_high: 0.0747, Time taken: 65.06\n","Save model at epoch 81\n","Epoch 82, \n","Epoch 82, Train_Loss: 0.3489, Val_Loss_low: 0.4031, Val_Loss_mid: 0.1357, Val_Loss_high: 0.0745, Time taken: 65.10\n","Save model at epoch 82\n","Epoch 83, \n","Epoch 83, Train_Loss: 0.3481, Val_Loss_low: 0.4000, Val_Loss_mid: 0.1364, Val_Loss_high: 0.0789, Time taken: 65.08\n","Epoch 84, \n","Epoch 84, Train_Loss: 0.3472, Val_Loss_low: 0.4025, Val_Loss_mid: 0.1388, Val_Loss_high: 0.0836, Time taken: 65.10\n","Epoch 85, \n","Epoch 85, Train_Loss: 0.3464, Val_Loss_low: 0.4048, Val_Loss_mid: 0.1410, Val_Loss_high: 0.0866, Time taken: 65.08\n","Epoch 86, \n","Epoch 86, Train_Loss: 0.3457, Val_Loss_low: 0.4088, Val_Loss_mid: 0.1437, Val_Loss_high: 0.0905, Time taken: 65.11\n","Epoch 87, \n","Epoch 87, Train_Loss: 0.3453, Val_Loss_low: 0.4059, Val_Loss_mid: 0.1463, Val_Loss_high: 0.0979, Time taken: 65.11\n","Epoch 88, \n","Epoch 88, Train_Loss: 0.3441, Val_Loss_low: 0.4057, Val_Loss_mid: 0.1476, Val_Loss_high: 0.1005, Time taken: 65.14\n","Epoch 89, \n","Epoch 89, Train_Loss: 0.3429, Val_Loss_low: 0.4075, Val_Loss_mid: 0.1479, Val_Loss_high: 0.1011, Time taken: 65.14\n","Epoch 90, \n","Epoch 90, Train_Loss: 0.3413, Val_Loss_low: 0.4078, Val_Loss_mid: 0.1479, Val_Loss_high: 0.1028, Time taken: 65.14\n","Epoch 91, \n","Epoch 91, Train_Loss: 0.3400, Val_Loss_low: 0.4142, Val_Loss_mid: 0.1507, Val_Loss_high: 0.1066, Time taken: 65.11\n","Epoch 92, \n","Epoch 92, Train_Loss: 0.3398, Val_Loss_low: 0.4169, Val_Loss_mid: 0.1530, Val_Loss_high: 0.1095, Time taken: 65.13\n","Epoch 93, \n","Epoch 93, Train_Loss: 0.3407, Val_Loss_low: 0.4198, Val_Loss_mid: 0.1536, Val_Loss_high: 0.1079, Time taken: 65.12\n","Epoch 94, \n","Epoch 94, Train_Loss: 0.3406, Val_Loss_low: 0.4132, Val_Loss_mid: 0.1546, Val_Loss_high: 0.1139, Time taken: 65.21\n","Epoch 95, \n","Epoch 95, Train_Loss: 0.3408, Val_Loss_low: 0.4153, Val_Loss_mid: 0.1509, Val_Loss_high: 0.1064, Time taken: 65.21\n","Epoch 96, \n","Epoch 96, Train_Loss: 0.3401, Val_Loss_low: 0.4160, Val_Loss_mid: 0.1525, Val_Loss_high: 0.1075, Time taken: 65.24\n","Epoch 97, \n","Epoch 97, Train_Loss: 0.3405, Val_Loss_low: 0.4144, Val_Loss_mid: 0.1448, Val_Loss_high: 0.0950, Time taken: 65.23\n","Epoch 98, \n","Epoch 98, Train_Loss: 0.3405, Val_Loss_low: 0.4131, Val_Loss_mid: 0.1471, Val_Loss_high: 0.0957, Time taken: 65.02\n","Epoch 99, \n","Epoch 99, Train_Loss: 0.3421, Val_Loss_low: 0.4067, Val_Loss_mid: 0.1433, Val_Loss_high: 0.0909, Time taken: 65.03\n","Epoch 100, \n","Epoch 100, Train_Loss: 0.3422, Val_Loss_low: 0.4165, Val_Loss_mid: 0.1452, Val_Loss_high: 0.0886, Time taken: 65.17\n","Epoch 101, \n","Epoch 101, Train_Loss: 0.3430, Val_Loss_low: 0.4254, Val_Loss_mid: 0.1434, Val_Loss_high: 0.0794, Time taken: 65.14\n","Epoch 102, \n","Epoch 102, Train_Loss: 0.3442, Val_Loss_low: 0.4118, Val_Loss_mid: 0.1393, Val_Loss_high: 0.0814, Time taken: 65.08\n","Epoch 103, \n","Epoch 103, Train_Loss: 0.3442, Val_Loss_low: 0.4119, Val_Loss_mid: 0.1406, Val_Loss_high: 0.0815, Time taken: 65.11\n","Epoch 104, \n","Epoch 104, Train_Loss: 0.3437, Val_Loss_low: 0.4033, Val_Loss_mid: 0.1419, Val_Loss_high: 0.0867, Time taken: 65.23\n","Epoch 105, \n","Epoch 105, Train_Loss: 0.3430, Val_Loss_low: 0.3940, Val_Loss_mid: 0.1387, Val_Loss_high: 0.0869, Time taken: 65.21\n","Epoch 106, \n","Epoch 106, Train_Loss: 0.3423, Val_Loss_low: 0.3933, Val_Loss_mid: 0.1373, Val_Loss_high: 0.0845, Time taken: 65.24\n","Epoch 107, \n","Epoch 107, Train_Loss: 0.3415, Val_Loss_low: 0.3941, Val_Loss_mid: 0.1368, Val_Loss_high: 0.0826, Time taken: 65.20\n","Epoch 108, \n","Epoch 108, Train_Loss: 0.3409, Val_Loss_low: 0.3961, Val_Loss_mid: 0.1365, Val_Loss_high: 0.0825, Time taken: 65.20\n","Epoch 109, \n","Epoch 109, Train_Loss: 0.3398, Val_Loss_low: 0.4026, Val_Loss_mid: 0.1381, Val_Loss_high: 0.0848, Time taken: 65.20\n","Epoch 110, \n","Epoch 110, Train_Loss: 0.3394, Val_Loss_low: 0.4078, Val_Loss_mid: 0.1394, Val_Loss_high: 0.0859, Time taken: 65.19\n","Epoch 111, \n","Epoch 111, Train_Loss: 0.3402, Val_Loss_low: 0.4113, Val_Loss_mid: 0.1413, Val_Loss_high: 0.0835, Time taken: 65.23\n","Epoch 112, \n","Epoch 112, Train_Loss: 0.3415, Val_Loss_low: 0.4082, Val_Loss_mid: 0.1423, Val_Loss_high: 0.0830, Time taken: 65.02\n","Epoch 113, \n","Epoch 113, Train_Loss: 0.3418, Val_Loss_low: 0.4070, Val_Loss_mid: 0.1395, Val_Loss_high: 0.0763, Time taken: 65.03\n","Epoch 114, \n","Epoch 114, Train_Loss: 0.3412, Val_Loss_low: 0.4075, Val_Loss_mid: 0.1412, Val_Loss_high: 0.0841, Time taken: 65.03\n","Epoch 115, \n","Epoch 115, Train_Loss: 0.3403, Val_Loss_low: 0.4076, Val_Loss_mid: 0.1407, Val_Loss_high: 0.0869, Time taken: 65.05\n","Epoch 116, \n","Epoch 116, Train_Loss: 0.3395, Val_Loss_low: 0.4051, Val_Loss_mid: 0.1406, Val_Loss_high: 0.0902, Time taken: 65.01\n","Epoch 117, \n","Epoch 117, Train_Loss: 0.3384, Val_Loss_low: 0.4038, Val_Loss_mid: 0.1412, Val_Loss_high: 0.0930, Time taken: 65.21\n","Epoch 118, \n","Epoch 118, Train_Loss: 0.3366, Val_Loss_low: 0.4026, Val_Loss_mid: 0.1428, Val_Loss_high: 0.0982, Time taken: 65.22\n","Epoch 119, \n","Epoch 119, Train_Loss: 0.3346, Val_Loss_low: 0.4066, Val_Loss_mid: 0.1451, Val_Loss_high: 0.1022, Time taken: 65.21\n","Epoch 120, \n","Epoch 120, Train_Loss: 0.3336, Val_Loss_low: 0.4095, Val_Loss_mid: 0.1480, Val_Loss_high: 0.1078, Time taken: 65.03\n","Epoch 121, \n","Epoch 121, Train_Loss: 0.3325, Val_Loss_low: 0.4119, Val_Loss_mid: 0.1497, Val_Loss_high: 0.1115, Time taken: 65.04\n","Epoch 122, \n","Epoch 122, Train_Loss: 0.3320, Val_Loss_low: 0.4163, Val_Loss_mid: 0.1518, Val_Loss_high: 0.1148, Time taken: 65.02\n","Epoch 123, \n","Epoch 123, Train_Loss: 0.3318, Val_Loss_low: 0.4182, Val_Loss_mid: 0.1532, Val_Loss_high: 0.1173, Time taken: 65.02\n","Epoch 124, \n","Epoch 124, Train_Loss: 0.3323, Val_Loss_low: 0.4201, Val_Loss_mid: 0.1513, Val_Loss_high: 0.1105, Time taken: 65.06\n","Epoch 125, \n","Epoch 125, Train_Loss: 0.3333, Val_Loss_low: 0.4176, Val_Loss_mid: 0.1521, Val_Loss_high: 0.1107, Time taken: 65.12\n","Epoch 126, \n","Epoch 126, Train_Loss: 0.3330, Val_Loss_low: 0.4206, Val_Loss_mid: 0.1563, Val_Loss_high: 0.1179, Time taken: 65.10\n","Epoch 127, \n","Epoch 127, Train_Loss: 0.3333, Val_Loss_low: 0.4163, Val_Loss_mid: 0.1458, Val_Loss_high: 0.0996, Time taken: 65.13\n","Epoch 128, \n","Epoch 128, Train_Loss: 0.3330, Val_Loss_low: 0.4136, Val_Loss_mid: 0.1450, Val_Loss_high: 0.0972, Time taken: 65.12\n","Epoch 129, \n","Epoch 129, Train_Loss: 0.3330, Val_Loss_low: 0.4087, Val_Loss_mid: 0.1494, Val_Loss_high: 0.1087, Time taken: 65.13\n","Epoch 130, \n","Epoch 130, Train_Loss: 0.3335, Val_Loss_low: 0.4163, Val_Loss_mid: 0.1553, Val_Loss_high: 0.1153, Time taken: 65.11\n","Epoch 131, \n","Epoch 131, Train_Loss: 0.3337, Val_Loss_low: 0.4106, Val_Loss_mid: 0.1494, Val_Loss_high: 0.1071, Time taken: 65.15\n","Epoch 132, \n","Epoch 132, Train_Loss: 0.3330, Val_Loss_low: 0.4136, Val_Loss_mid: 0.1452, Val_Loss_high: 0.0985, Time taken: 65.11\n","Epoch 133, \n","Epoch 133, Train_Loss: 0.3331, Val_Loss_low: 0.4159, Val_Loss_mid: 0.1444, Val_Loss_high: 0.0961, Time taken: 65.12\n","Epoch 134, \n","Epoch 134, Train_Loss: 0.3341, Val_Loss_low: 0.4107, Val_Loss_mid: 0.1403, Val_Loss_high: 0.0881, Time taken: 65.10\n","Epoch 135, \n","Epoch 135, Train_Loss: 0.3341, Val_Loss_low: 0.4071, Val_Loss_mid: 0.1393, Val_Loss_high: 0.0875, Time taken: 65.13\n","Epoch 136, \n","Epoch 136, Train_Loss: 0.3346, Val_Loss_low: 0.4052, Val_Loss_mid: 0.1364, Val_Loss_high: 0.0817, Time taken: 65.13\n","Epoch 137, \n","Epoch 137, Train_Loss: 0.3348, Val_Loss_low: 0.4067, Val_Loss_mid: 0.1362, Val_Loss_high: 0.0787, Time taken: 65.09\n","Epoch 138, \n","Epoch 138, Train_Loss: 0.3350, Val_Loss_low: 0.4102, Val_Loss_mid: 0.1412, Val_Loss_high: 0.0843, Time taken: 65.10\n","Epoch 139, \n","Epoch 139, Train_Loss: 0.3357, Val_Loss_low: 0.4166, Val_Loss_mid: 0.1443, Val_Loss_high: 0.0867, Time taken: 65.13\n","Epoch 140, \n","Epoch 140, Train_Loss: 0.3363, Val_Loss_low: 0.3964, Val_Loss_mid: 0.1398, Val_Loss_high: 0.0894, Time taken: 65.11\n","Epoch 141, \n","Epoch 141, Train_Loss: 0.3370, Val_Loss_low: 0.4007, Val_Loss_mid: 0.1413, Val_Loss_high: 0.0908, Time taken: 65.09\n","Epoch 142, \n","Epoch 142, Train_Loss: 0.3376, Val_Loss_low: 0.4156, Val_Loss_mid: 0.1422, Val_Loss_high: 0.0879, Time taken: 65.11\n","Epoch 143, \n","Epoch 143, Train_Loss: 0.3379, Val_Loss_low: 0.4155, Val_Loss_mid: 0.1413, Val_Loss_high: 0.0876, Time taken: 65.07\n","Epoch 144, \n","Epoch 144, Train_Loss: 0.3375, Val_Loss_low: 0.4122, Val_Loss_mid: 0.1432, Val_Loss_high: 0.0935, Time taken: 65.11\n","Epoch 145, \n","Epoch 145, Train_Loss: 0.3368, Val_Loss_low: 0.4070, Val_Loss_mid: 0.1412, Val_Loss_high: 0.0924, Time taken: 65.11\n","Epoch 146, \n","Epoch 146, Train_Loss: 0.3360, Val_Loss_low: 0.4029, Val_Loss_mid: 0.1392, Val_Loss_high: 0.0903, Time taken: 65.12\n","Epoch 147, \n","Epoch 147, Train_Loss: 0.3350, Val_Loss_low: 0.4008, Val_Loss_mid: 0.1387, Val_Loss_high: 0.0909, Time taken: 65.11\n","Epoch 148, \n","Epoch 148, Train_Loss: 0.3333, Val_Loss_low: 0.3993, Val_Loss_mid: 0.1383, Val_Loss_high: 0.0915, Time taken: 65.10\n","Epoch 149, \n","Epoch 149, Train_Loss: 0.3309, Val_Loss_low: 0.3998, Val_Loss_mid: 0.1387, Val_Loss_high: 0.0931, Time taken: 65.11\n","Epoch 150, \n","Epoch 150, Train_Loss: 0.3291, Val_Loss_low: 0.4038, Val_Loss_mid: 0.1415, Val_Loss_high: 0.0979, Time taken: 65.11\n","Epoch 151, \n","Epoch 151, Train_Loss: 0.3278, Val_Loss_low: 0.4103, Val_Loss_mid: 0.1455, Val_Loss_high: 0.1039, Time taken: 65.13\n","Epoch 152, \n","Epoch 152, Train_Loss: 0.3272, Val_Loss_low: 0.4147, Val_Loss_mid: 0.1476, Val_Loss_high: 0.1074, Time taken: 65.13\n","Epoch 153, \n","Epoch 153, Train_Loss: 0.3268, Val_Loss_low: 0.4188, Val_Loss_mid: 0.1494, Val_Loss_high: 0.1108, Time taken: 65.14\n","Epoch 154, \n","Epoch 154, Train_Loss: 0.3268, Val_Loss_low: 0.4236, Val_Loss_mid: 0.1539, Val_Loss_high: 0.1162, Time taken: 65.15\n","Epoch 155, \n","Epoch 155, Train_Loss: 0.3321, Val_Loss_low: 0.4127, Val_Loss_mid: 0.1470, Val_Loss_high: 0.1058, Time taken: 65.13\n","Epoch 156, \n","Epoch 156, Train_Loss: 0.3264, Val_Loss_low: 0.4157, Val_Loss_mid: 0.1479, Val_Loss_high: 0.1074, Time taken: 65.15\n","Epoch 157, \n","Epoch 157, Train_Loss: 0.3259, Val_Loss_low: 0.4180, Val_Loss_mid: 0.1486, Val_Loss_high: 0.1088, Time taken: 65.15\n","Epoch 158, \n","Epoch 158, Train_Loss: 0.3267, Val_Loss_low: 0.4203, Val_Loss_mid: 0.1530, Val_Loss_high: 0.1144, Time taken: 65.17\n","Epoch 159, \n","Epoch 159, Train_Loss: 0.3288, Val_Loss_low: 0.4332, Val_Loss_mid: 0.1493, Val_Loss_high: 0.1039, Time taken: 65.14\n","Epoch 160, \n","Epoch 160, Train_Loss: 0.3282, Val_Loss_low: 0.4102, Val_Loss_mid: 0.1426, Val_Loss_high: 0.0960, Time taken: 65.13\n","Epoch 161, \n","Epoch 161, Train_Loss: 0.3283, Val_Loss_low: 0.4114, Val_Loss_mid: 0.1426, Val_Loss_high: 0.0933, Time taken: 65.16\n","Epoch 162, \n","Epoch 162, Train_Loss: 0.3280, Val_Loss_low: 0.4071, Val_Loss_mid: 0.1453, Val_Loss_high: 0.1021, Time taken: 65.13\n","Epoch 163, \n","Epoch 163, Train_Loss: 0.3285, Val_Loss_low: 0.4060, Val_Loss_mid: 0.1450, Val_Loss_high: 0.1015, Time taken: 65.14\n","Epoch 164, \n","Epoch 164, Train_Loss: 0.3283, Val_Loss_low: 0.4061, Val_Loss_mid: 0.1427, Val_Loss_high: 0.0951, Time taken: 65.12\n","Epoch 165, \n","Epoch 165, Train_Loss: 0.3281, Val_Loss_low: 0.4094, Val_Loss_mid: 0.1416, Val_Loss_high: 0.0923, Time taken: 65.15\n","Epoch 166, \n","Epoch 166, Train_Loss: 0.3279, Val_Loss_low: 0.4198, Val_Loss_mid: 0.1414, Val_Loss_high: 0.0893, Time taken: 65.10\n","Epoch 167, \n","Epoch 167, Train_Loss: 0.3283, Val_Loss_low: 0.4167, Val_Loss_mid: 0.1393, Val_Loss_high: 0.0859, Time taken: 65.10\n","Epoch 168, \n","Epoch 168, Train_Loss: 0.3292, Val_Loss_low: 0.4212, Val_Loss_mid: 0.1405, Val_Loss_high: 0.0837, Time taken: 65.10\n","Epoch 169, \n","Epoch 169, Train_Loss: 0.3299, Val_Loss_low: 0.4105, Val_Loss_mid: 0.1399, Val_Loss_high: 0.0859, Time taken: 65.11\n","Epoch 170, \n","Epoch 170, Train_Loss: 0.3302, Val_Loss_low: 0.4044, Val_Loss_mid: 0.1412, Val_Loss_high: 0.0919, Time taken: 65.10\n","Epoch 171, \n","Epoch 171, Train_Loss: 0.3308, Val_Loss_low: 0.4117, Val_Loss_mid: 0.1406, Val_Loss_high: 0.0878, Time taken: 65.08\n","Epoch 172, \n","Epoch 172, Train_Loss: 0.3316, Val_Loss_low: 0.4141, Val_Loss_mid: 0.1440, Val_Loss_high: 0.0926, Time taken: 65.25\n","Epoch 173, \n","Epoch 173, Train_Loss: 0.3320, Val_Loss_low: 0.4173, Val_Loss_mid: 0.1490, Val_Loss_high: 0.0993, Time taken: 65.21\n","Epoch 174, \n","Epoch 174, Train_Loss: 0.3334, Val_Loss_low: 0.4069, Val_Loss_mid: 0.1415, Val_Loss_high: 0.0893, Time taken: 65.20\n","Epoch 175, \n","Epoch 175, Train_Loss: 0.3347, Val_Loss_low: 0.3995, Val_Loss_mid: 0.1386, Val_Loss_high: 0.0864, Time taken: 65.19\n","Epoch 176, \n","Epoch 176, Train_Loss: 0.3345, Val_Loss_low: 0.3962, Val_Loss_mid: 0.1356, Val_Loss_high: 0.0814, Time taken: 65.20\n","Epoch 177, \n","Epoch 177, Train_Loss: 0.3339, Val_Loss_low: 0.3971, Val_Loss_mid: 0.1352, Val_Loss_high: 0.0797, Time taken: 65.20\n","Epoch 178, \n","Epoch 178, Train_Loss: 0.3337, Val_Loss_low: 0.3964, Val_Loss_mid: 0.1346, Val_Loss_high: 0.0787, Time taken: 65.07\n","Epoch 179, \n","Epoch 179, Train_Loss: 0.3333, Val_Loss_low: 0.3960, Val_Loss_mid: 0.1343, Val_Loss_high: 0.0783, Time taken: 65.10\n","Epoch 180, \n","Epoch 180, Train_Loss: 0.3327, Val_Loss_low: 0.3952, Val_Loss_mid: 0.1337, Val_Loss_high: 0.0782, Time taken: 65.08\n","Epoch 181, \n","Epoch 181, Train_Loss: 0.3320, Val_Loss_low: 0.3948, Val_Loss_mid: 0.1334, Val_Loss_high: 0.0781, Time taken: 65.14\n","Epoch 182, \n","Epoch 182, Train_Loss: 0.3310, Val_Loss_low: 0.3958, Val_Loss_mid: 0.1337, Val_Loss_high: 0.0789, Time taken: 65.13\n","Epoch 183, \n","Epoch 183, Train_Loss: 0.3294, Val_Loss_low: 0.3974, Val_Loss_mid: 0.1342, Val_Loss_high: 0.0805, Time taken: 65.11\n","Epoch 184, \n","Epoch 184, Train_Loss: 0.3268, Val_Loss_low: 0.4005, Val_Loss_mid: 0.1348, Val_Loss_high: 0.0821, Time taken: 65.10\n","Epoch 185, \n","Epoch 185, Train_Loss: 0.3251, Val_Loss_low: 0.4037, Val_Loss_mid: 0.1374, Val_Loss_high: 0.0873, Time taken: 65.13\n","Epoch 186, \n","Epoch 186, Train_Loss: 0.3238, Val_Loss_low: 0.4075, Val_Loss_mid: 0.1406, Val_Loss_high: 0.0935, Time taken: 65.16\n","Epoch 187, \n","Epoch 187, Train_Loss: 0.3230, Val_Loss_low: 0.4136, Val_Loss_mid: 0.1446, Val_Loss_high: 0.0998, Time taken: 65.14\n","Epoch 188, \n","Epoch 188, Train_Loss: 0.3227, Val_Loss_low: 0.4182, Val_Loss_mid: 0.1460, Val_Loss_high: 0.1024, Time taken: 65.13\n","Epoch 189, \n","Epoch 189, Train_Loss: 0.3224, Val_Loss_low: 0.4223, Val_Loss_mid: 0.1471, Val_Loss_high: 0.1042, Time taken: 65.13\n","Epoch 190, \n","Epoch 190, Train_Loss: 0.3228, Val_Loss_low: 0.4265, Val_Loss_mid: 0.1494, Val_Loss_high: 0.1067, Time taken: 65.12\n","Epoch 191, \n","Epoch 191, Train_Loss: 0.3233, Val_Loss_low: 0.4235, Val_Loss_mid: 0.1483, Val_Loss_high: 0.1048, Time taken: 65.15\n","Epoch 192, \n","Epoch 192, Train_Loss: 0.3236, Val_Loss_low: 0.4201, Val_Loss_mid: 0.1489, Val_Loss_high: 0.1063, Time taken: 65.11\n","Epoch 193, \n","Epoch 193, Train_Loss: 0.3237, Val_Loss_low: 0.4181, Val_Loss_mid: 0.1533, Val_Loss_high: 0.1138, Time taken: 65.10\n","Epoch 194, \n","Epoch 194, Train_Loss: 0.3239, Val_Loss_low: 0.4141, Val_Loss_mid: 0.1438, Val_Loss_high: 0.0974, Time taken: 65.09\n","Epoch 195, \n","Epoch 195, Train_Loss: 0.3239, Val_Loss_low: 0.4154, Val_Loss_mid: 0.1421, Val_Loss_high: 0.0941, Time taken: 65.21\n","Epoch 196, \n"]}],"source":["if not pretrained:\n","  pre_batch_loss = 1e9\n","  for epoch in range(EPOCHS):\n","      start_time = time.time()\n","      batch_loss = np.array([])\n","      batch_val_loss_low = np.array([])\n","      batch_val_loss_mid = np.array([])\n","      batch_val_loss_high = np.array([])\n","      print(\n","        f'Epoch {epoch}, '\n","      )\n","\n","    # Load batch data for 4RB training\n","      for iter, (index, esno_db, c, y, b,r, y_r) in enumerate(train_set_low):\n","          # calculate loss and optimize\n","          loss = train_step(y_r, c)\n","          batch_loss = np.append(batch_loss, loss)\n","\n","\n","      # Load batch data for 4RB validating\n","      for iter, (index, esno_db, c, y, b,r, y_r) in enumerate(test_set_low):\n","          loss_val = val_step(y_r, c)\n","          batch_val_loss_low = np.append(batch_val_loss_low, loss_val)\n","\n","      for iter, (index, esno_db, c, y, b,r, y_r) in enumerate(test_set_mid):\n","          loss_val = val_step(y_r, c)\n","          batch_val_loss_mid = np.append(batch_val_loss_mid, loss_val)\n","\n","      for iter, (index, esno_db, c, y, b,r, y_r) in enumerate(test_set_high):\n","          loss_val = val_step(y_r, c)\n","          batch_val_loss_high = np.append(batch_val_loss_high, loss_val)\n","\n","\n","      # Write batch loss to log file\n","      train_batch_loss(tf.reduce_mean(batch_loss))\n","      with train_summary_writer.as_default():\n","        tf.summary.scalar('BCE_Epoch_Loss', train_batch_loss.result(), step=epoch+134)\n","\n","      val_batch_loss_low(tf.reduce_mean(batch_val_loss_low))\n","      with val_summary_writer.as_default():\n","        tf.summary.scalar('BCE_Epoch_Loss', val_batch_loss_low.result(), step=epoch+134)\n","\n","      val_batch_loss_mid(tf.reduce_mean(batch_val_loss_mid))\n","      with val_summary_writer.as_default():\n","        tf.summary.scalar('BCE_Epoch_Loss', val_batch_loss_mid.result(), step=epoch+134)\n","\n","      val_batch_loss_high(tf.reduce_mean(batch_val_loss_high))\n","      with val_summary_writer.as_default():\n","        tf.summary.scalar('BCE_Epoch_Loss', val_batch_loss_high.result(), step=epoch+134)\n","\n","      time_taken = time.time() - start_time\n","      print(\n","          f'Epoch {epoch}, '\n","          f'Train_Loss: {train_batch_loss.result():0.4f}, '\n","          f'Val_Loss_low: {val_batch_loss_low.result():0.4f}, '\n","          f'Val_Loss_mid: {val_batch_loss_mid.result():0.4f}, '\n","          f'Val_Loss_high: {val_batch_loss_high.result():0.4f}, '\n","          f'Time taken: {time_taken:0.2f}'\n","      )\n","\n","      if pre_batch_loss >= val_batch_loss_high.result():\n","        pre_batch_loss = val_batch_loss_high.result()\n","        model_file_name = f\"weight_4RB_high_SNR_dynamic_config.pkl\"\n","        save_weights(model, model_folder_path, model_file_name)\n","        print(\n","            f'Save model at epoch {epoch}'\n","        )\n","\n","      train_batch_loss.reset_state()\n","      val_batch_loss_low.reset_state()\n","      val_batch_loss_mid.reset_state()\n","      val_batch_loss_high.reset_state()\n"]},{"cell_type":"markdown","id":"wzgzsX_Zs9-3","metadata":{"id":"wzgzsX_Zs9-3"},"source":["* **Save weight**"]},{"cell_type":"code","execution_count":null,"id":"scbnGQGKqQRO","metadata":{"id":"scbnGQGKqQRO"},"outputs":[],"source":["    # Save the weights in a file\n","model_folder_path = \"/content/drive/MyDrive/AI_for_PUSCH/VHT_neural_receiver/\"\n","model_file_name = \"weight_4RB_UMI_dynamic_config.pkl\"\n","save_weights(model, model_folder_path, model_file_name)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1L4UGLYGtYC7z7Gsmsx3fY7RZ3yboLa-y","timestamp":1739113707037},{"file_id":"https://github.com/nvlabs/sionna/blob/main/examples/Neural_Receiver.ipynb","timestamp":1737450903303}],"gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}